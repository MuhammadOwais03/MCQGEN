{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6525efb5-2e60-4cfd-8b37-9f7167d904d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfde4b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd6ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_base_url = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ceec729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26e86bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am a language model AI trained to assist with various tasks such as answering questions, providing information, and engaging in conversation. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-3.5-turbo-16k\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response = llm([HumanMessage(content=\"Hello! What can you do?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3674821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import openai\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55a0d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7cf4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "692b9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4483c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=['text', 'number', 'subject', 'tone', 'response_json'],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c1d7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c9fec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73b109fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c01dc88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_chain = SequentialChain(chains=[chain1, chain2], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25e1bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/owais/MyProjects/GEN_AI/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5143c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05d384cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.[29][30]\\n\\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[31]\\n\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[32][33] Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[34] process plans for manufacturing[32] and decision plans such as in prototype autonomous spacecraft.[35]\\n\\nSince inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.[36]\\n\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\n\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[37] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[38] This was followed in 2019 by GPT-2, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[39]\\n\\nThe new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.[40]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d81b99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 10\n",
    "SUBJECT = \"Generative AI\"\n",
    "TONE = \"normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c3eb597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21908/550409977.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response=quiz_evaluation_chain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:The first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.[29][30]\n",
      "\n",
      "Computers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[31]\n",
      "\n",
      "The terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[32][33] Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[34] process plans for manufacturing[32] and decision plans such as in prototype autonomous spacecraft.[35]\n",
      "\n",
      "Since inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.[36]\n",
      "\n",
      "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n",
      "\n",
      "In 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[37] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[38] This was followed in 2019 by GPT-2, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[39]\n",
      "\n",
      "The new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.[40]\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 10 multiple choice questions for Generative AI students in normal tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 10 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for Generative AI students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"Which Russian mathematician is credited with the development of Markov chains?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Andrey Markov\",\n",
      "            \"b\": \"Harold Cohen\",\n",
      "            \"c\": \"Eugeny Onegin\",\n",
      "            \"d\": \"Variational autoencoder\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"What was the first text corpus that Andrey Markov analyzed using Markov chains?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Eugeny Onegin\",\n",
      "            \"b\": \"AARON\",\n",
      "            \"c\": \"GPT-2\",\n",
      "            \"d\": \"Transformer network\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"Which computer program was created by Harold Cohen to generate paintings?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"AARON\",\n",
      "            \"b\": \"Generative adversarial network\",\n",
      "            \"c\": \"Deep learning\",\n",
      "            \"d\": \"State space search\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"mcq\": \"What technology was considered relatively mature in the early 1990s for generating crisis action plans for military use?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Variational autoencoder\",\n",
      "            \"b\": \"Generative AI planning systems\",\n",
      "            \"c\": \"Markov chains\",\n",
      "            \"d\": \"GPT-1\"\n",
      "        },\n",
      "        \"correct\": \"b\"\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"mcq\": \"Which technology was used to generate process plans for manufacturing in the 1980s and 1990s?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Constraint satisfaction\",\n",
      "            \"b\": \"Neural networks\",\n",
      "            \"c\": \"Generative models\",\n",
      "            \"d\": \"Deep learning\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"mcq\": \"What advancements in 2014 allowed for the first practical deep neural networks capable of learning generative models for complex data?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Markov chains\",\n",
      "            \"b\": \"Variational autoencoder\",\n",
      "            \"c\": \"Deep learning\",\n",
      "            \"d\": \"Generative adversarial network\"\n",
      "        },\n",
      "        \"correct\": \"b\"\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"mcq\": \"Which network enabled advancements in generative models compared to older Long-Short Term Memory models in 2017?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Markov chains\",\n",
      "            \"b\": \"GPT-1\",\n",
      "            \"c\": \"Variational autoencoder\",\n",
      "            \"d\": \"Transformer network\"\n",
      "        },\n",
      "        \"correct\": \"d\"\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"mcq\": \"What was the first generative pre-trained transformer known as in 2018?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"GPT-1\",\n",
      "            \"b\": \"Generative adversarial network\",\n",
      "            \"c\": \"Deep learning\",\n",
      "            \"d\": \"AARON\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"mcq\": \"Which model demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model in 2019?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"GPT-1\",\n",
      "            \"b\": \"GPT-2\",\n",
      "            \"c\": \"Transformer network\",\n",
      "            \"d\": \"Generative models\"\n",
      "        },\n",
      "        \"correct\": \"b\"\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"mcq\": \"What did unsupervised learning enable in the training of large neural networks?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Manual labeling of data\",\n",
      "            \"b\": \"Use of discriminative models\",\n",
      "            \"c\": \"Generative modeling\",\n",
      "            \"d\": \"Constraint satisfaction\"\n",
      "        },\n",
      "        \"correct\": \"c\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response=quiz_evaluation_chain(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a9809a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:2656\n",
      "Prompt Tokens:1777\n",
      "Completion Tokens:879\n",
      "Total Cost:0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b2f496b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.[29][30]\\n\\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[31]\\n\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[32][33] Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[34] process plans for manufacturing[32] and decision plans such as in prototype autonomous spacecraft.[35]\\n\\nSince inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.[36]\\n\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\n\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[37] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[38] This was followed in 2019 by GPT-2, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[39]\\n\\nThe new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.[40]',\n",
       " 'number': 10,\n",
       " 'subject': 'Generative AI',\n",
       " 'tone': 'normal',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '{\\n    \"1\": {\\n        \"mcq\": \"Which Russian mathematician is credited with the development of Markov chains?\",\\n        \"options\": {\\n            \"a\": \"Andrey Markov\",\\n            \"b\": \"Harold Cohen\",\\n            \"c\": \"Eugeny Onegin\",\\n            \"d\": \"Variational autoencoder\"\\n        },\\n        \"correct\": \"a\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"What was the first text corpus that Andrey Markov analyzed using Markov chains?\",\\n        \"options\": {\\n            \"a\": \"Eugeny Onegin\",\\n            \"b\": \"AARON\",\\n            \"c\": \"GPT-2\",\\n            \"d\": \"Transformer network\"\\n        },\\n        \"correct\": \"a\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"Which computer program was created by Harold Cohen to generate paintings?\",\\n        \"options\": {\\n            \"a\": \"AARON\",\\n            \"b\": \"Generative adversarial network\",\\n            \"c\": \"Deep learning\",\\n            \"d\": \"State space search\"\\n        },\\n        \"correct\": \"a\"\\n    },\\n    \"4\": {\\n        \"mcq\": \"What technology was considered relatively mature in the early 1990s for generating crisis action plans for military use?\",\\n        \"options\": {\\n            \"a\": \"Variational autoencoder\",\\n            \"b\": \"Generative AI planning systems\",\\n            \"c\": \"Markov chains\",\\n            \"d\": \"GPT-1\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"5\": {\\n        \"mcq\": \"Which technology was used to generate process plans for manufacturing in the 1980s and 1990s?\",\\n        \"options\": {\\n            \"a\": \"Constraint satisfaction\",\\n            \"b\": \"Neural networks\",\\n            \"c\": \"Generative models\",\\n            \"d\": \"Deep learning\"\\n        },\\n        \"correct\": \"a\"\\n    },\\n    \"6\": {\\n        \"mcq\": \"What advancements in 2014 allowed for the first practical deep neural networks capable of learning generative models for complex data?\",\\n        \"options\": {\\n            \"a\": \"Markov chains\",\\n            \"b\": \"Variational autoencoder\",\\n            \"c\": \"Deep learning\",\\n            \"d\": \"Generative adversarial network\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"7\": {\\n        \"mcq\": \"Which network enabled advancements in generative models compared to older Long-Short Term Memory models in 2017?\",\\n        \"options\": {\\n            \"a\": \"Markov chains\",\\n            \"b\": \"GPT-1\",\\n            \"c\": \"Variational autoencoder\",\\n            \"d\": \"Transformer network\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"8\": {\\n        \"mcq\": \"What was the first generative pre-trained transformer known as in 2018?\",\\n        \"options\": {\\n            \"a\": \"GPT-1\",\\n            \"b\": \"Generative adversarial network\",\\n            \"c\": \"Deep learning\",\\n            \"d\": \"AARON\"\\n        },\\n        \"correct\": \"a\"\\n    },\\n    \"9\": {\\n        \"mcq\": \"Which model demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model in 2019?\",\\n        \"options\": {\\n            \"a\": \"GPT-1\",\\n            \"b\": \"GPT-2\",\\n            \"c\": \"Transformer network\",\\n            \"d\": \"Generative models\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"10\": {\\n        \"mcq\": \"What did unsupervised learning enable in the training of large neural networks?\",\\n        \"options\": {\\n            \"a\": \"Manual labeling of data\",\\n            \"b\": \"Use of discriminative models\",\\n            \"c\": \"Generative modeling\",\\n            \"d\": \"Constraint satisfaction\"\\n        },\\n        \"correct\": \"c\"\\n    }\\n}',\n",
       " 'review': 'The quiz is highly complex, focusing on advanced topics in generative AI. The questions require deep understanding of concepts and terminology. To better fit student abilities, simplify questions, provide more context, and use simpler language.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8fe8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = json.loads(response.get(\"quiz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e5a84b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'mcq': 'Which Russian mathematician is credited with the development of Markov chains?',\n",
       "  'options': {'a': 'Andrey Markov',\n",
       "   'b': 'Harold Cohen',\n",
       "   'c': 'Eugeny Onegin',\n",
       "   'd': 'Variational autoencoder'},\n",
       "  'correct': 'a'},\n",
       " '2': {'mcq': 'What was the first text corpus that Andrey Markov analyzed using Markov chains?',\n",
       "  'options': {'a': 'Eugeny Onegin',\n",
       "   'b': 'AARON',\n",
       "   'c': 'GPT-2',\n",
       "   'd': 'Transformer network'},\n",
       "  'correct': 'a'},\n",
       " '3': {'mcq': 'Which computer program was created by Harold Cohen to generate paintings?',\n",
       "  'options': {'a': 'AARON',\n",
       "   'b': 'Generative adversarial network',\n",
       "   'c': 'Deep learning',\n",
       "   'd': 'State space search'},\n",
       "  'correct': 'a'},\n",
       " '4': {'mcq': 'What technology was considered relatively mature in the early 1990s for generating crisis action plans for military use?',\n",
       "  'options': {'a': 'Variational autoencoder',\n",
       "   'b': 'Generative AI planning systems',\n",
       "   'c': 'Markov chains',\n",
       "   'd': 'GPT-1'},\n",
       "  'correct': 'b'},\n",
       " '5': {'mcq': 'Which technology was used to generate process plans for manufacturing in the 1980s and 1990s?',\n",
       "  'options': {'a': 'Constraint satisfaction',\n",
       "   'b': 'Neural networks',\n",
       "   'c': 'Generative models',\n",
       "   'd': 'Deep learning'},\n",
       "  'correct': 'a'},\n",
       " '6': {'mcq': 'What advancements in 2014 allowed for the first practical deep neural networks capable of learning generative models for complex data?',\n",
       "  'options': {'a': 'Markov chains',\n",
       "   'b': 'Variational autoencoder',\n",
       "   'c': 'Deep learning',\n",
       "   'd': 'Generative adversarial network'},\n",
       "  'correct': 'b'},\n",
       " '7': {'mcq': 'Which network enabled advancements in generative models compared to older Long-Short Term Memory models in 2017?',\n",
       "  'options': {'a': 'Markov chains',\n",
       "   'b': 'GPT-1',\n",
       "   'c': 'Variational autoencoder',\n",
       "   'd': 'Transformer network'},\n",
       "  'correct': 'd'},\n",
       " '8': {'mcq': 'What was the first generative pre-trained transformer known as in 2018?',\n",
       "  'options': {'a': 'GPT-1',\n",
       "   'b': 'Generative adversarial network',\n",
       "   'c': 'Deep learning',\n",
       "   'd': 'AARON'},\n",
       "  'correct': 'a'},\n",
       " '9': {'mcq': 'Which model demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model in 2019?',\n",
       "  'options': {'a': 'GPT-1',\n",
       "   'b': 'GPT-2',\n",
       "   'c': 'Transformer network',\n",
       "   'd': 'Generative models'},\n",
       "  'correct': 'b'},\n",
       " '10': {'mcq': 'What did unsupervised learning enable in the training of large neural networks?',\n",
       "  'options': {'a': 'Manual labeling of data',\n",
       "   'b': 'Use of discriminative models',\n",
       "   'c': 'Generative modeling',\n",
       "   'd': 'Constraint satisfaction'},\n",
       "  'correct': 'c'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8be28449",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = response.get(\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a2f84b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quiz is highly complex, focusing on advanced topics in generative AI. The questions require deep understanding of concepts and terminology. To better fit student abilities, simplify questions, provide more context, and use simpler language.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa07ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e2ee544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'Which Russian mathematician is credited with the development of Markov chains?',\n",
       "  'Choices': 'a: Andrey Markov | b: Harold Cohen | c: Eugeny Onegin | d: Variational autoencoder',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'What was the first text corpus that Andrey Markov analyzed using Markov chains?',\n",
       "  'Choices': 'a: Eugeny Onegin | b: AARON | c: GPT-2 | d: Transformer network',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'Which computer program was created by Harold Cohen to generate paintings?',\n",
       "  'Choices': 'a: AARON | b: Generative adversarial network | c: Deep learning | d: State space search',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'What technology was considered relatively mature in the early 1990s for generating crisis action plans for military use?',\n",
       "  'Choices': 'a: Variational autoencoder | b: Generative AI planning systems | c: Markov chains | d: GPT-1',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which technology was used to generate process plans for manufacturing in the 1980s and 1990s?',\n",
       "  'Choices': 'a: Constraint satisfaction | b: Neural networks | c: Generative models | d: Deep learning',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'What advancements in 2014 allowed for the first practical deep neural networks capable of learning generative models for complex data?',\n",
       "  'Choices': 'a: Markov chains | b: Variational autoencoder | c: Deep learning | d: Generative adversarial network',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which network enabled advancements in generative models compared to older Long-Short Term Memory models in 2017?',\n",
       "  'Choices': 'a: Markov chains | b: GPT-1 | c: Variational autoencoder | d: Transformer network',\n",
       "  'Correct': 'd'},\n",
       " {'MCQ': 'What was the first generative pre-trained transformer known as in 2018?',\n",
       "  'Choices': 'a: GPT-1 | b: Generative adversarial network | c: Deep learning | d: AARON',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'Which model demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model in 2019?',\n",
       "  'Choices': 'a: GPT-1 | b: GPT-2 | c: Transformer network | d: Generative models',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'What did unsupervised learning enable in the training of large neural networks?',\n",
       "  'Choices': 'a: Manual labeling of data | b: Use of discriminative models | c: Generative modeling | d: Constraint satisfaction',\n",
       "  'Correct': 'c'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "663938dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f55bf000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCQ</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which Russian mathematician is credited with t...</td>\n",
       "      <td>a: Andrey Markov | b: Harold Cohen | c: Eugeny...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the first text corpus that Andrey Mar...</td>\n",
       "      <td>a: Eugeny Onegin | b: AARON | c: GPT-2 | d: Tr...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which computer program was created by Harold C...</td>\n",
       "      <td>a: AARON | b: Generative adversarial network |...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What technology was considered relatively matu...</td>\n",
       "      <td>a: Variational autoencoder | b: Generative AI ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which technology was used to generate process ...</td>\n",
       "      <td>a: Constraint satisfaction | b: Neural network...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MCQ  \\\n",
       "0  Which Russian mathematician is credited with t...   \n",
       "1  What was the first text corpus that Andrey Mar...   \n",
       "2  Which computer program was created by Harold C...   \n",
       "3  What technology was considered relatively matu...   \n",
       "4  Which technology was used to generate process ...   \n",
       "\n",
       "                                             Choices Correct  \n",
       "0  a: Andrey Markov | b: Harold Cohen | c: Eugeny...       a  \n",
       "1  a: Eugeny Onegin | b: AARON | c: GPT-2 | d: Tr...       a  \n",
       "2  a: AARON | b: Generative adversarial network |...       a  \n",
       "3  a: Variational autoencoder | b: Generative AI ...       b  \n",
       "4  a: Constraint satisfaction | b: Neural network...       a  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88841f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(f\"{SUBJECT}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c4ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
